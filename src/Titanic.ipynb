{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'test.csv', 'train.csv', 'gender_submission.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf # use it to train the module\n",
    "from sklearn.preprocessing import LabelEncoder # encoder to make the dataset as number\n",
    "from sklearn.preprocessing import OneHotEncoder # encoder to make the dataset as one hot\n",
    "from sklearn.utils import shuffle # use for shuffle the data\n",
    "from sklearn.model_selection import train_test_split # split the data set\n",
    "from sklearn.preprocessing import normalize # use to normalize the data set\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "# get the training se\n",
    "df_origin = pd.read_csv(\"../input/train.csv\")\n",
    "train_df = df_origin.copy()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the data set to X_train and Y_train\n",
    "# Y_train = train_df['Survived']\n",
    "# X_train = train_df.drop(['Survived'], axis=1)\n",
    "# print('X_train: ', X_train.shape)\n",
    "# print('Y_train: ', X_train.shape)\n",
    "# print('-------------')\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    False\n",
      "Survived       False\n",
      "Pclass         False\n",
      "Name           False\n",
      "Sex            False\n",
      "Age             True\n",
      "SibSp          False\n",
      "Parch          False\n",
      "Ticket         False\n",
      "Fare           False\n",
      "Cabin           True\n",
      "Embarked        True\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.isnull().any())\n",
    "\n",
    "# get the data distribution\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the sex to binary value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      891\n",
      "unique       2\n",
      "top       male\n",
      "freq       577\n",
      "Name: Sex, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Sex'].describe())\n",
    "#print(np.bincount(X_train['Sex']))\n",
    "\n",
    "# set the sex to binary value\n",
    "# le_sex = LabelEncoder().fit(train_df['Sex'])\n",
    "# Sex_label = le_sex.transform(train_df['Sex']) # don't give the result to dataframe directely, we need to one hot encode later\n",
    "# # Set the sex to on-hot\n",
    "# #    545                     \"Reshape your data either using array.reshape(-1, 1) if \"\n",
    "# #     546                     \"your data has a single feature or array.reshape(1, -1) \"\n",
    "# # --> 547                     \"if it contains a single sample.\".format(array))\n",
    "# # categories='auto' is follow the warning instruction\n",
    "# OH_sex = OneHotEncoder(sparse=False, categories='auto')\n",
    "# Sex_label = OH_sex.fit_transform(Sex_label.reshape(-1, 1 ))\n",
    "\n",
    "# print(Sex_label)\n",
    "# #train_df['Sex_Lable'] = Sex_label\n",
    "# train_df['Sex_Lable'] = np.NaN\n",
    "# train_df['Sex_Lable'] = Sex_label\n",
    "\n",
    "# print(train_df['Sex_Lable'].iloc[0])\n",
    "# print(train_df['Sex_Lable'].iloc[0].dtype)\n",
    "############ old method #########################\n",
    "# X_train['Sex_binary'] = X_train['Sex'] == 'male'\n",
    "# #X_train['Sex_binary'].head()\n",
    "# X_train['Sex_binary'] = X_train['Sex_binary'].astype('int')\n",
    "# #X_train['Sex'].head()\n",
    "\n",
    "# print(X_train['Sex_binary'].describe())\n",
    "# # check the covariance\n",
    "# print(np.cov(X_train['Sex_binary'], train_df.Survived))\n",
    "sex_df = pd.get_dummies(df_origin['Sex'], columns='Sex', prefix='Sex')\n",
    "train_df = pd.concat([train_df, sex_df], axis=1, sort=False)\n",
    "train_df = train_df.drop(['Sex'], axis=1)\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering on Embarked\n",
    "\n",
    "# deal with the NaN or just use the NaN as a feature\n",
    "# print(df_origin['Embarked'].isnull().any())\n",
    "# Embarked_nan_mask = df_origin['Embarked'].isnull()\n",
    "# #Try using .loc[row_indexer,col_indexer] = value instead\n",
    "# Embarked_lable = train_df['Embarked'].copy()\n",
    "# Embarked_lable[Embarked_nan_mask] = 'N'\n",
    "# train_df['Embarked_lable'] = Embarked_lable\n",
    "# print(train_df['Embarked_lable'].isnull().any())\n",
    "# print(train_df[Embarked_nan_mask])\n",
    "eb_df = pd.get_dummies(df_origin['Embarked'], columns='Embarked', dummy_na=True, prefix='Embarked')\n",
    "train_df = pd.concat([train_df, eb_df], axis=1, sort=False)\n",
    "train_df = train_df.drop(['Embarked'], axis=1)\n",
    "\n",
    "\n",
    "#one hot encode\n",
    "# le_Eb = LabelEncoder().fit(train_df['Embarked_lable'])\n",
    "# train_df['Embarked_lable'] = le_Eb.transform(train_df['Embarked_lable']) # don't give the result to dataframe directely, we need to one hot encode later\n",
    "# #print(train_df['Embarked_lable'])\n",
    "\n",
    "# # categories='auto' is follow the warning instruction\n",
    "# #  sklearn 的新版本中，OneHotEncoder 的输入必须是 2-D array，而 testdata.age 返回的 Series 本质上是 1-D array，所以要改成\n",
    "# # \n",
    "# a = OneHotEncoder(sparse=False, categories='auto').fit_transform(train_df[['Embarked_lable']])\n",
    "# print(a)\n",
    "\n",
    "\n",
    "#print(train_df['Embarked_lable'])\n",
    "#train_df['Sex_Lable'] = Sex_label\n",
    "#train_df['Embarked_lable'] = Eb_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count             204\n",
      "unique            147\n",
      "top       C23 C25 C27\n",
      "freq                4\n",
      "Name: Cabin, dtype: object\n",
      "nan is  <class 'float'>\n",
      "C85 is  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# deal with the Cabin\n",
    "print(df_origin['Cabin'].describe())\n",
    "print(df_origin['Cabin'][0], 'is ', type(df_origin['Cabin'][0]))\n",
    "print(df_origin['Cabin'][1], 'is ', type(df_origin['Cabin'][1]))\n",
    "\n",
    "# the nan in cabin type is float\n",
    "# cabin_nan_mask = df_origin['Cabin'].isna()\n",
    "# print(cabin_nan_mask)\n",
    "# df_origin[cabin_nan_mask]\n",
    "\n",
    "def get_cabin_level(x):\n",
    "    #print(x)\n",
    "    if x == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return x[0]\n",
    "\n",
    "# make the NaN to 0\n",
    "train_df['Cabin_label']= train_df['Cabin'].fillna(0)\n",
    "    \n",
    "# # modify to cabin level, such as C23 to level C\n",
    "train_df['Cabin_label'] = train_df['Cabin_label'].map(get_cabin_level)\n",
    "#train_df = train_df.drop(['Cabin'], axis=1)\n",
    "\n",
    "cb_df = pd.get_dummies(train_df['Cabin_label'], columns='Cabin_label', dummy_na=True, prefix='Cabin')\n",
    "train_df = pd.concat([train_df, cb_df], axis=1, sort=False)\n",
    "train_df = train_df.drop(['Cabin_label'], axis=1)  \n",
    "train_df = train_df.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with the age\n",
    "train_df['Age_label']= np.floor(train_df['Age'].fillna(np.mean(df_origin['Age'])))\n",
    "train_df = train_df.drop(['Age'], axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneed column\n",
    "train_df = train_df.drop(['Name', 'Ticket', 'PassengerId'], axis=1)\n",
    "\n",
    "# shuffle the data\n",
    "train_df = shuffle(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the fare\n",
    "f_temp = train_df['Fare'].fillna(np.mean(df_origin['Fare']))\n",
    "fare_max = np.max(f_temp)\n",
    "fare_min = np.min(f_temp)\n",
    "train_df['Fare'] = f_temp.apply(lambda x: (x - fare_min) / (fare_max - fare_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 712\n",
      "number of test examples = 179\n",
      "X_train shape: (712, 21)\n",
      "Y_train shape: (712,)\n",
      "X_test shape: (179, 21)\n",
      "Y_test shape: (179,)\n"
     ]
    }
   ],
   "source": [
    "Y = train_df['Survived'].values\n",
    "X = train_df.drop(['Survived'], axis=1).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "m_feature = X_train.shape[1]\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_function = None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    \n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    \n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "        \n",
    "    return outputs\n",
    "\n",
    "xs = tf.placeholder(tf.float32,  [None, m_feature])\n",
    "ys = tf.placeholder(tf.int32,  [None])\n",
    "# add relu here\n",
    "#l1 = add_layer(xs, m_feature, 5, activation_function=tf.nn.sigmoid)\n",
    "logits = add_layer(xs, m_feature, 2, activation_function=tf.nn.sigmoid)\n",
    "predict = tf.arg_max(logits, 1)\n",
    "\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(logits=logits,labels=ys)\n",
    "loss = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "\n",
    "_, acc_op = tf.metrics.accuracy(labels=ys,predictions=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6932179927825928, acc = 0.6348314881324768\n",
      "loss = 0.48382022976875305, acc = 0.7868171334266663\n",
      "loss = 0.4761705696582794, acc = 0.8052294254302979\n",
      "loss = 0.47204533219337463, acc = 0.8132410645484924\n",
      "loss = 0.46928173303604126, acc = 0.8171696662902832\n",
      "loss = 0.4671750068664551, acc = 0.8181925415992737\n",
      "loss = 0.46563708782196045, acc = 0.8186657428741455\n",
      "loss = 0.4644258916378021, acc = 0.8188884258270264\n",
      "loss = 0.46338826417922974, acc = 0.8190013766288757\n",
      "loss = 0.46245309710502625, acc = 0.8187944889068604\n",
      "val acc = [0.8186644]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    for epoch in range(10000): # 训练次数\n",
    "        loss_value,_ ,acc_value= sess.run([loss,optimizer,acc_op],feed_dict={xs:X_train,ys:Y_train})\n",
    "        if epoch%1000 == 0:\n",
    "            print('loss = {}, acc = {}'.format(loss_value,acc_value))\n",
    "    acc_value = sess.run([acc_op],feed_dict={xs:X_test,ys:Y_test}) # 验证集的精度，这里验证集和\n",
    "    print('val acc = {}'.format(acc_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
